{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5afca213e3fd4a905a1ee04cf013c4a2a70ed6bf52820ba3c074a5841fff5c71"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 在猫变虎的融合过程中，可以看出由于两者的“五官”位置差距较大，所以我们需要先找到特征区域，在对图片做仿射变换，使得特征区域可以对上，之后再进行Addweight操作，这样可能最终效果会比较好\n",
    "\n",
    "### 下面是我参考了github以及论坛资源关于人脸融合的资料，在其基础上理解并改写的人脸融合程序。\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import Delaunay\n",
    "predictor_model = 'shape_predictor_68_face_landmarks.dat'\n",
    "## 使用dlib官网提供的提取人脸68个特征点的模型\n",
    "\n",
    "def get_points(image):  # 用 dlib 来得到人脸的特征点\n",
    "\n",
    "    face_detector = dlib.get_frontal_face_detector()  # 提取脸外部矩形框\n",
    "    face_pose_predictor = dlib.shape_predictor(predictor_model) # 根据官网提供的68个人脸特征提取点代码 构造预测器\n",
    "    detected_face = face_detector(image, 1)[0]\n",
    "    print(detected_face)\n",
    "    pose_landmarks = face_pose_predictor(image, detected_face)  # 获取特征\n",
    "    points = []\n",
    "    for p in pose_landmarks.parts():\n",
    "        points.append([p.x, p.y])\n",
    "    ## 记录特征点的位置\n",
    "    # 加入四个顶点和四条边的中点\n",
    "    x = image.shape[1] - 1\n",
    "    y = image.shape[0] - 1\n",
    "    points.append([0, 0])\n",
    "    points.append([x // 2, 0])\n",
    "    points.append([x, 0])\n",
    "    points.append([x, y // 2])\n",
    "    points.append([x, y])\n",
    "    points.append([x // 2, y])\n",
    "    points.append([0, y])\n",
    "    points.append([0, y // 2])\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "\n",
    "def get_triangles(points):  #  在特征点上使用 Delaunay 三角剖分，将点集连接成一定大小的三角形，且分配要相对合理，才能呈现出漂亮的三角化\n",
    "    return Delaunay(points).simplices\n",
    "\n",
    "\n",
    "def affine_transform(input_image, input_triangle, output_triangle, size):  # 这里就是针对三角形进行仿射变化的函数（调用opencv关于仿射变换的库函数），传入的是输入图片，输入特征三角形，输出特征三角形以及输出图片尺寸。对人脸进行仿射变换，确定位置\n",
    "    warp_matrix = cv2.getAffineTransform(np.float32(input_triangle), np.float32(output_triangle))\n",
    "    output_image = cv2.warpAffine(input_image, warp_matrix, (size[0], size[1]), None，                  flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return output_image\n",
    "\n",
    "\n",
    "def morph_triangle(img1, img2, img, tri1, tri2, tri, alpha):  # 三角形变形，Alpha 混合\n",
    "    # 计算三角形的边界框\n",
    "    rect1 = cv2.boundingRect(np.float32([tri1]))  # 寻找tri1的左上角坐标，和tri1的长和宽\n",
    "    rect2 = cv2.boundingRect(np.float32([tri2]))\n",
    "    rect = cv2.boundingRect(np.float32([tri]))\n",
    "\n",
    "    tri_rect1 = []\n",
    "    tri_rect2 = []\n",
    "    tri_rect_warped = []\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        tri_rect_warped.append(\n",
    "            ((tri[i][0] - rect[0]), (tri[i][1] - rect[1])))\n",
    "        tri_rect1.append(\n",
    "            ((tri1[i][0] - rect1[0]), (tri1[i][1] - rect1[1])))\n",
    "        tri_rect2.append(\n",
    "            ((tri2[i][0] - rect2[0]), (tri2[i][1] - rect2[1])))\n",
    "\n",
    "    # 在边界框内进行仿射变换\n",
    "    img1_rect = img1[rect1[1]:rect1[1] +\n",
    "                     rect1[3], rect1[0]:rect1[0] + rect1[2]]\n",
    "    img2_rect = img2[rect2[1]:rect2[1] +\n",
    "                     rect2[3], rect2[0]:rect2[0] + rect2[2]]\n",
    "\n",
    "    size = (rect[2], rect[3])\n",
    "    warped_img1 = affine_transform(\n",
    "        img1_rect, tri_rect1, tri_rect_warped, size)\n",
    "    warped_img2 = affine_transform(\n",
    "        img2_rect, tri_rect2, tri_rect_warped, size)\n",
    "\n",
    "    # 加权求和\n",
    "    img_rect = (1.0 - alpha) * warped_img1 + alpha * warped_img2\n",
    "## 我们在这种三角形区域（包含特征多的区域）进行加权融合，保证融合出来主要是特征区域\n",
    "    # 生成模板\n",
    "    mask = np.zeros((rect[3], rect[2], 3), dtype=np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(tri_rect_warped), (1.0, 1.0, 1.0), 16, 0)\n",
    "\n",
    "    # 应用模板\n",
    "    img[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]] = \\\n",
    "        img[rect[1]:rect[1] + rect[3], rect[0]:rect[0] +\n",
    "            rect[2]] * (1 - mask) + img_rect * mask\n",
    "\n",
    "\n",
    "def morph_faces(filename1, filename2, alpha=0.5):  # 融合图片\n",
    "    img1 = cv2.imread(filename1)\n",
    "    img2 = cv2.imread(filename2)\n",
    "    img2 = cv2.resize(img2,(img1.shape[1],img1.shape[0]),interpolation=cv2.INTER_CUBIC)\n",
    "    print('img1.shape',img1.shape)\n",
    "    print('img2.shape',img2.shape)\n",
    "\n",
    "    points1 = get_points(img1)\n",
    "    print('pionts1:',len(points1),points1)\n",
    "    points2 = get_points(img2)\n",
    "    points = (1 - alpha) * np.array(points1) + alpha * np.array(points2)\n",
    "\n",
    "    img1 = np.float32(img1)\n",
    "    img2 = np.float32(img2)\n",
    "    img_morphed = np.zeros(img1.shape, dtype=img1.dtype)\n",
    "\n",
    "    triangles = get_triangles(points)\n",
    "    for i in triangles:\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        z = i[2]\n",
    "\n",
    "        tri1 = [points1[x], points1[y], points1[z]]\n",
    "        tri2 = [points2[x], points2[y], points2[z]]\n",
    "        tri = [points[x], points[y], points[z]]\n",
    "        morph_triangle(img1, img2, img_morphed, tri1, tri2, tri, alpha)\n",
    "\n",
    "    return np.uint8(img_morphed)\n",
    "\n",
    "\n",
    "def main(file1,file2,alpha):\n",
    "    try:\n",
    "     alpha = float(alpha)\n",
    "    except:\n",
    "        alpha = 0.5\n",
    "    img_morphed = morph_faces(file1, file2, alpha)\n",
    "    output_file = '{}_{}_{}.jpg'.format(\n",
    "        file1.split('.')[0][-2:], file2.split('.')[0][-2:], alpha)\n",
    "    cv2.imwrite(output_file, img_morphed)\n",
    "    return output_file\n",
    "\n",
    "# main('zch.png','zzy.png',0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(280, 502) (946, 1168)]\n"
     ]
    }
   ],
   "source": [
    "zzy_img = cv2.imread('zzy.png')\n",
    "zzy_points = get_points(zzy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "img1.shape (275, 183, 3)\n",
      "img2.shape (275, 183, 3)\n",
      "[(56, 66) (145, 156)]\n",
      "pionts1: 76 [[ 58  84]\n",
      " [ 57  95]\n",
      " [ 57 106]\n",
      " [ 58 117]\n",
      " [ 61 128]\n",
      " [ 66 139]\n",
      " [ 72 148]\n",
      " [ 80 156]\n",
      " [ 89 159]\n",
      " [ 99 158]\n",
      " [108 153]\n",
      " [116 145]\n",
      " [123 137]\n",
      " [128 127]\n",
      " [132 117]\n",
      " [135 106]\n",
      " [137  95]\n",
      " [ 67  79]\n",
      " [ 74  77]\n",
      " [ 82  78]\n",
      " [ 89  81]\n",
      " [ 95  84]\n",
      " [106  84]\n",
      " [114  83]\n",
      " [121  82]\n",
      " [128  83]\n",
      " [132  88]\n",
      " [100  92]\n",
      " [ 99 100]\n",
      " [ 98 107]\n",
      " [ 97 115]\n",
      " [ 89 119]\n",
      " [ 92 121]\n",
      " [ 96 122]\n",
      " [ 99 122]\n",
      " [103 121]\n",
      " [ 75  88]\n",
      " [ 80  87]\n",
      " [ 85  88]\n",
      " [ 88  92]\n",
      " [ 84  92]\n",
      " [ 79  91]\n",
      " [109  95]\n",
      " [113  92]\n",
      " [118  92]\n",
      " [122  95]\n",
      " [118  97]\n",
      " [113  97]\n",
      " [ 80 132]\n",
      " [ 86 131]\n",
      " [ 91 130]\n",
      " [ 94 132]\n",
      " [ 98 131]\n",
      " [102 133]\n",
      " [106 136]\n",
      " [101 138]\n",
      " [ 97 139]\n",
      " [ 93 139]\n",
      " [ 89 138]\n",
      " [ 85 135]\n",
      " [ 82 133]\n",
      " [ 90 134]\n",
      " [ 94 135]\n",
      " [ 98 135]\n",
      " [104 136]\n",
      " [ 98 134]\n",
      " [ 94 134]\n",
      " [ 90 133]\n",
      " [  0   0]\n",
      " [ 91   0]\n",
      " [182   0]\n",
      " [182 137]\n",
      " [182 274]\n",
      " [ 91 274]\n",
      " [  0 274]\n",
      " [  0 137]]\n",
      "[(38, 96) (167, 225)]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'yy_zy_0.5.jpg'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "main('pyy.png','zzy.png',0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}